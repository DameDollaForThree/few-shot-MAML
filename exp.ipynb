{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a17a1627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from few_shot.datasets import OmniglotDataset, MiniImageNet\n",
    "from few_shot.core import NShotTaskSampler, create_nshot_task_label, EvaluateFewShot\n",
    "from few_shot.maml import meta_gradient_step\n",
    "from few_shot.models import FewShotClassifier\n",
    "from few_shot.train import fit\n",
    "from few_shot.callbacks import *\n",
    "from few_shot.utils import setup_dirs\n",
    "from config import PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a35b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    n = 1\n",
    "    k = 5\n",
    "    q = 5\n",
    "    inner_train_steps = 2\n",
    "    inner_val_steps = 1\n",
    "    inner_lr = 0.01\n",
    "    meta_lr = 0.001\n",
    "    meta_batch_size = 1\n",
    "    order = 2\n",
    "    epochs = 1\n",
    "    epoch_len = 5\n",
    "    eval_batches = 1\n",
    "    \n",
    "    dataset = 'miniImageNet'\n",
    "#     dataset = 'omniglot'\n",
    "    gpu = 1\n",
    "    \n",
    "args = Args()\n",
    "    \n",
    "assert torch.cuda.is_available()\n",
    "torch.cuda.set_device(args.gpu)\n",
    "device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7ec0612",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset == 'omniglot':\n",
    "    dataset_class = OmniglotDataset\n",
    "    fc_layer_size = 64\n",
    "    num_input_channels = 1\n",
    "elif args.dataset == 'miniImageNet':\n",
    "    dataset_class = MiniImageNet\n",
    "    fc_layer_size = 1600\n",
    "    num_input_channels = 3\n",
    "else:\n",
    "    raise(ValueError('Unsupported dataset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aad2024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing background...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48000it [00:00, 564358.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12000it [00:00, 594803.15it/s]\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# Create datasets #\n",
    "###################\n",
    "\n",
    "background = dataset_class('background')\n",
    "background_taskloader = DataLoader(\n",
    "    background,\n",
    "    batch_sampler=NShotTaskSampler(background, args.epoch_len, n=args.n, k=args.k, q=args.q,\n",
    "                                   num_tasks=args.meta_batch_size),\n",
    "    num_workers=8\n",
    ")\n",
    "evaluation = dataset_class('evaluation')\n",
    "evaluation_taskloader = DataLoader(\n",
    "    evaluation,\n",
    "    batch_sampler=NShotTaskSampler(evaluation, args.eval_batches, n=args.n, k=args.k, q=args.q,\n",
    "                                   num_tasks=args.meta_batch_size),\n",
    "    num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3266e264",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model_ori = FewShotClassifier(num_input_channels, args.k, fc_layer_size).to(device, dtype=torch.double)\n",
    "meta_model_new = FewShotClassifier(num_input_channels, args.k, fc_layer_size).to(device, dtype=torch.double)\n",
    "\n",
    "optimiser_ori = torch.optim.Adam(meta_model_origin.parameters(), lr=args.meta_lr)\n",
    "optimiser_new = torch.optim.Adam(meta_model_new.parameters(), lr=args.meta_lr)\n",
    "conv_optimiser_new = torch.optim.Adam(meta_model_new.conv_param, lr=args.meta_lr)\n",
    "other_optimiser_new = torch.optim.Adam(meta_model_new.other_param, lr=args.meta_lr)\n",
    "\n",
    "loss_fn_ori = nn.CrossEntropyLoss().to(device)\n",
    "loss_fn_new = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3841943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_meta_batch(n, k, q, meta_batch_size):\n",
    "    def prepare_meta_batch_(batch):\n",
    "        x, y = batch\n",
    "\n",
    "        # Reshape to `meta_batch_size` number of tasks. Each task contains\n",
    "        # n*k support samples to train the fast model on and q*k query samples to\n",
    "        # evaluate the fast model on and generate meta-gradients\n",
    "        x = x.reshape(meta_batch_size, n*k + q*k, num_input_channels, x.shape[-2], x.shape[-1])\n",
    "        # Move to device\n",
    "        x = x.double().to(device)\n",
    "        # Create label\n",
    "        y = create_nshot_task_label(k, q).cuda().repeat(meta_batch_size)\n",
    "        return x, y\n",
    "\n",
    "    return prepare_meta_batch_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "937a78cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30, 3, 84, 84])\n",
      "torch.Size([25])\n",
      "original:  tensor([ 0.1233,  0.1583, -0.1633], device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "new:  tensor([ 0.1233,  0.1583, -0.1633], device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 30, 3, 84, 84])\n",
      "torch.Size([25])\n",
      "original:  tensor([ 0.1233,  0.1583, -0.1633], device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "new:  tensor([ 0.1233,  0.1583, -0.1633], device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 30, 3, 84, 84])\n",
      "torch.Size([25])\n",
      "original:  tensor([ 0.1233,  0.1583, -0.1633], device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "new:  tensor([ 0.1233,  0.1583, -0.1633], device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 30, 3, 84, 84])\n",
      "torch.Size([25])\n",
      "original:  tensor([ 0.1233,  0.1583, -0.1633], device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "new:  tensor([ 0.1233,  0.1583, -0.1633], device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 30, 3, 84, 84])\n",
      "torch.Size([25])\n",
      "original:  tensor([ 0.1233,  0.1583, -0.1633], device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "new:  tensor([ 0.1233,  0.1583, -0.1633], device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dataloader=background_taskloader,\n",
    "prepare_batch=prepare_meta_batch(args.n, args.k, args.q, args.meta_batch_size)\n",
    "fit_function=meta_gradient_step,\n",
    "fit_function_kwargs={'n_shot': args.n, 'k_way': args.k, 'q_queries': args.q,\n",
    "                     'train': True,\n",
    "                     'order': args.order, 'device': device, 'inner_train_steps': args.inner_train_steps,\n",
    "                     'inner_lr': args.inner_lr}\n",
    "    \n",
    "for epoch in range(1, args.epochs+1):\n",
    "    for batch_index, batch in enumerate(dataloader[0]):\n",
    "        x, y = prepare_batch(batch)\n",
    "\n",
    "#         loss_origin, y_pred_origin = fit_function[0](meta_model_origin, optimiser_origin, loss_fn_origin, \n",
    "#                                                      x, y, origin=True, **fit_function_kwargs)\n",
    "        \n",
    "        loss_new, y_pred_new = fit_function[0](meta_model_new, optimiser_new, loss_fn_new, x, y, origin=True, \n",
    "                                               other_optim=[conv_optimiser_new, other_optimiser_new], \n",
    "                                               p_task=[1,1,1,1], p_meta=[1,1,1,1], **fit_function_kwargs)\n",
    "        print(meta_model_new.conv1[0].bias.grad[0])\n",
    "        \n",
    "        loss_new, y_pred_new = fit_function[0](meta_model_new, optimiser_new, loss_fn_new, x, y, origin=False, \n",
    "                                               other_optim=[conv_optimiser_new, other_optimiser_new], \n",
    "                                               p_task=[1,1,1,1], p_meta=[1,1,1,1], **fit_function_kwargs)\n",
    "        print(meta_model_new.conv1[0].bias.grad[0])\n",
    "        \n",
    "#         print('loss_origin: ', loss_origin)\n",
    "#         print('y_pred_origin', y_pred_origin)\n",
    "#         print('loss_new: ', loss_new)\n",
    "#         print('y_pred_new', y_pred_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17f35be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1276a637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b375419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dac7126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526b44a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
