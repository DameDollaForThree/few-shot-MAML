{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c9a8db",
   "metadata": {},
   "source": [
    "# Original Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef7da79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "from torch.optim import Optimizer\n",
    "from torch.nn import Module\n",
    "from typing import Dict, List, Callable, Union\n",
    "\n",
    "from few_shot.core import create_nshot_task_label\n",
    "\n",
    "\n",
    "def replace_grad(parameter_gradients, parameter_name):\n",
    "    def replace_grad_(module):\n",
    "        return parameter_gradients[parameter_name]\n",
    "\n",
    "    return replace_grad_\n",
    "\n",
    "\n",
    "def meta_gradient_step_ori(model: Module,\n",
    "                       optimiser: Optimizer,\n",
    "                       loss_fn: Callable,\n",
    "                       x: torch.Tensor,\n",
    "                       y: torch.Tensor,\n",
    "                       n_shot: int,\n",
    "                       k_way: int,\n",
    "                       q_queries: int,\n",
    "                       order: int,\n",
    "                       inner_train_steps: int,\n",
    "                       inner_lr: float,\n",
    "                       train: bool,\n",
    "                       device: Union[str, torch.device]):\n",
    "    \"\"\"\n",
    "    Perform a gradient step on a meta-learner.\n",
    "\n",
    "    # Arguments\n",
    "        model: Base model of the meta-learner being trained\n",
    "        optimiser: Optimiser to calculate gradient step from loss\n",
    "        loss_fn: Loss function to calculate between predictions and outputs\n",
    "        x: Input samples for all few shot tasks\n",
    "        y: Input labels of all few shot tasks\n",
    "        n_shot: Number of examples per class in the support set of each task\n",
    "        k_way: Number of classes in the few shot classification task of each task\n",
    "        q_queries: Number of examples per class in the query set of each task. The query set is used to calculate\n",
    "            meta-gradients after applying the update to\n",
    "        order: Whether to use 1st order MAML (update meta-learner weights with gradients of the updated weights on the\n",
    "            query set) or 2nd order MAML (use 2nd order updates by differentiating through the gradients of the updated\n",
    "            weights on the query with respect to the original weights).\n",
    "        inner_train_steps: Number of gradient steps to fit the fast weights during each inner update\n",
    "        inner_lr: Learning rate used to update the fast weights on the inner update\n",
    "        train: Whether to update the meta-learner weights at the end of the episode.\n",
    "        device: Device on which to run computation\n",
    "    \"\"\"\n",
    "    data_shape = x.shape[2:]\n",
    "    create_graph = (True if order == 2 else False) and train\n",
    "\n",
    "    task_gradients = []\n",
    "    task_losses = []\n",
    "    task_predictions = []\n",
    "    for meta_batch in x:\n",
    "        # By construction x is a 5D tensor of shape: (meta_batch_size, n*k + q*k, channels, width, height)\n",
    "        # Hence when we iterate over the first  dimension we are iterating through the meta batches\n",
    "        x_task_train = meta_batch[:n_shot * k_way]\n",
    "        x_task_val = meta_batch[n_shot * k_way:]\n",
    "\n",
    "        # Create a fast model using the current meta model weights\n",
    "        fast_weights = OrderedDict(model.named_parameters())\n",
    "\n",
    "        # Train the model for `inner_train_steps` iterations\n",
    "        for inner_batch in range(inner_train_steps):\n",
    "            # Perform update of model weights\n",
    "            y = create_nshot_task_label(k_way, n_shot).to(device)\n",
    "            logits = model.functional_forward(x_task_train, fast_weights)\n",
    "            loss = loss_fn(logits, y)\n",
    "            gradients = torch.autograd.grad(loss, fast_weights.values(), create_graph=create_graph)\n",
    "\n",
    "            # Update weights manually\n",
    "            fast_weights = OrderedDict(\n",
    "                (name, param - inner_lr * grad)\n",
    "                for ((name, param), grad) in zip(fast_weights.items(), gradients)\n",
    "            )\n",
    "\n",
    "        # Do a pass of the model on the validation data from the current task\n",
    "        y = create_nshot_task_label(k_way, q_queries).to(device)\n",
    "        logits = model.functional_forward(x_task_val, fast_weights)\n",
    "        loss = loss_fn(logits, y)\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "        # Get post-update accuracies\n",
    "        y_pred = logits.softmax(dim=1)\n",
    "        task_predictions.append(y_pred)\n",
    "\n",
    "        # Accumulate losses and gradients\n",
    "        task_losses.append(loss)\n",
    "        gradients = torch.autograd.grad(loss, fast_weights.values(), create_graph=create_graph)\n",
    "        named_grads = {name: g for ((name, _), g) in zip(fast_weights.items(), gradients)}\n",
    "        task_gradients.append(named_grads)\n",
    "\n",
    "    if order == 1:\n",
    "        if train:\n",
    "            sum_task_gradients = {k: torch.stack([grad[k] for grad in task_gradients]).mean(dim=0)\n",
    "                                  for k in task_gradients[0].keys()}\n",
    "            hooks = []\n",
    "            for name, param in model.named_parameters():\n",
    "                hooks.append(\n",
    "                    param.register_hook(replace_grad(sum_task_gradients, name))\n",
    "                )\n",
    "\n",
    "            model.train()\n",
    "            optimiser.zero_grad()\n",
    "            # Dummy pass in order to create `loss` variable\n",
    "            # Replace dummy gradients with mean task gradients using hooks\n",
    "            logits = model(torch.zeros((k_way, ) + data_shape).to(device, dtype=torch.double))\n",
    "            loss = loss_fn(logits, create_nshot_task_label(k_way, 1).to(device))\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            for h in hooks:\n",
    "                h.remove()\n",
    "\n",
    "        return torch.stack(task_losses).mean(), torch.cat(task_predictions)\n",
    "\n",
    "    elif order == 2:\n",
    "        model.train()\n",
    "        optimiser.zero_grad()\n",
    "        meta_batch_loss = torch.stack(task_losses).mean()\n",
    "\n",
    "        if train:\n",
    "            meta_batch_loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "        return meta_batch_loss, torch.cat(task_predictions)\n",
    "    else:\n",
    "        raise ValueError('Order must be either 1 or 2.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a6f9f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from typing import Dict\n",
    "\n",
    "def conv_block(in_channels: int, out_channels: int) -> nn.Module:\n",
    "    \"\"\"Returns a Module that performs 3x3 convolution, ReLu activation, 2x2 max pooling.\n",
    "    # Arguments\n",
    "        in_channels:\n",
    "        out_channels:\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    )\n",
    "\n",
    "\n",
    "def functional_conv_block(x: torch.Tensor, weights: torch.Tensor, biases: torch.Tensor,\n",
    "                          bn_weights, bn_biases) -> torch.Tensor:\n",
    "    \"\"\"Performs 3x3 convolution, ReLu activation, 2x2 max pooling in a functional fashion.\n",
    "    # Arguments:\n",
    "        x: Input Tensor for the conv block\n",
    "        weights: Weights for the convolutional block\n",
    "        biases: Biases for the convolutional block\n",
    "        bn_weights:\n",
    "        bn_biases:\n",
    "    \"\"\"\n",
    "    x = F.conv2d(x, weights, biases, padding=1)\n",
    "    x = F.batch_norm(x, running_mean=None, running_var=None, weight=bn_weights, bias=bn_biases, training=True)\n",
    "    x = F.relu(x)\n",
    "    x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "    return x\n",
    "\n",
    "class FewShotClassifierOri(nn.Module):\n",
    "    def __init__(self, num_input_channels: int, k_way: int, final_layer_size: int = 64):\n",
    "        \"\"\"Creates a few shot classifier as used in MAML.\n",
    "        This network should be identical to the one created by `get_few_shot_encoder` but with a\n",
    "        classification layer on top.\n",
    "        # Arguments:\n",
    "            num_input_channels: Number of color channels the model expects input data to contain. Omniglot = 1,\n",
    "                miniImageNet = 3\n",
    "            k_way: Number of classes the model will discriminate between\n",
    "            final_layer_size: 64 for Omniglot, 1600 for miniImageNet\n",
    "        \"\"\"\n",
    "        super(FewShotClassifierOri, self).__init__()\n",
    "        self.conv1 = conv_block(num_input_channels, 64)\n",
    "        self.conv2 = conv_block(64, 64)\n",
    "        self.conv3 = conv_block(64, 64)\n",
    "        self.conv4 = conv_block(64, 64)\n",
    "\n",
    "        self.logits = nn.Linear(final_layer_size, k_way)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return self.logits(x)\n",
    "\n",
    "    def functional_forward(self, x, weights):\n",
    "        \"\"\"Applies the same forward pass using PyTorch functional operators using a specified set of weights.\"\"\"\n",
    "\n",
    "        for block in [1, 2, 3, 4]:\n",
    "            x = functional_conv_block(x, weights[f'conv{block}.0.weight'], weights[f'conv{block}.0.bias'],\n",
    "                                      weights.get(f'conv{block}.1.weight'), weights.get(f'conv{block}.1.bias'))\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = F.linear(x, weights['logits.weight'], weights['logits.bias'])\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d3c0a6",
   "metadata": {},
   "source": [
    "# Our Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7dd2e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from few_shot.datasets import OmniglotDataset, MiniImageNet\n",
    "from few_shot.core import NShotTaskSampler, create_nshot_task_label, EvaluateFewShot\n",
    "from few_shot.maml import meta_gradient_step\n",
    "from few_shot.models import FewShotClassifier\n",
    "from few_shot.train import fit\n",
    "from few_shot.callbacks import *\n",
    "from few_shot.utils import setup_dirs\n",
    "from config import PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "417eea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    n = 1\n",
    "    k = 5\n",
    "    q = 5\n",
    "    inner_train_steps = 2\n",
    "    inner_val_steps = 1\n",
    "    inner_lr = 0.01\n",
    "    meta_lr = 0.01\n",
    "    meta_batch_size = 1\n",
    "    order = 2\n",
    "    epochs = 1\n",
    "    epoch_len = 2\n",
    "    eval_batches = 1\n",
    "    \n",
    "    dataset = 'miniImageNet'\n",
    "#     dataset = 'omniglot'\n",
    "    gpu = 1\n",
    "    \n",
    "args = Args()\n",
    "    \n",
    "assert torch.cuda.is_available()\n",
    "torch.cuda.set_device(args.gpu)\n",
    "device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3922e7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset == 'omniglot':\n",
    "    dataset_class = OmniglotDataset\n",
    "    fc_layer_size = 64\n",
    "    num_input_channels = 1\n",
    "elif args.dataset == 'miniImageNet':\n",
    "    dataset_class = MiniImageNet\n",
    "    fc_layer_size = 1600\n",
    "    num_input_channels = 3\n",
    "else:\n",
    "    raise(ValueError('Unsupported dataset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46712408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing background...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48000it [00:00, 550665.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12000it [00:00, 579423.80it/s]\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# Create datasets #\n",
    "###################\n",
    "\n",
    "background = dataset_class('background')\n",
    "background_taskloader = DataLoader(\n",
    "    background,\n",
    "    batch_sampler=NShotTaskSampler(background, args.epoch_len, n=args.n, k=args.k, q=args.q,\n",
    "                                   num_tasks=args.meta_batch_size),\n",
    "    num_workers=8\n",
    ")\n",
    "evaluation = dataset_class('evaluation')\n",
    "evaluation_taskloader = DataLoader(\n",
    "    evaluation,\n",
    "    batch_sampler=NShotTaskSampler(evaluation, args.eval_batches, n=args.n, k=args.k, q=args.q,\n",
    "                                   num_tasks=args.meta_batch_size),\n",
    "    num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b10b0c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model_ori = FewShotClassifierOri(num_input_channels, args.k, fc_layer_size).to(device, dtype=torch.double)\n",
    "meta_model_new = FewShotClassifierOri(num_input_channels, args.k, fc_layer_size).to(device, dtype=torch.double)\n",
    "# meta_model_new = FewShotClassifier(num_input_channels, args.k, fc_layer_size).to(device, dtype=torch.double)\n",
    "\n",
    "# optimiser_ori = torch.optim.Adam(meta_model_ori.parameters(), lr=args.meta_lr)\n",
    "# optimiser_new = torch.optim.Adam(meta_model_new.parameters(), lr=args.meta_lr)\n",
    "# conv_optimiser_new = torch.optim.Adam(meta_model_new.conv_param, lr=args.meta_lr)\n",
    "# other_optimiser_new = torch.optim.Adam(meta_model_new.other_param, lr=args.meta_lr)\n",
    "\n",
    "optimiser_ori = torch.optim.SGD(meta_model_ori.parameters(), lr=args.meta_lr)\n",
    "optimiser_new = torch.optim.SGD(meta_model_new.parameters(), lr=args.meta_lr)\n",
    "# conv_optimiser_new = torch.optim.SGD(meta_model_new.conv_param, lr=args.meta_lr)\n",
    "# other_optimiser_new = torch.optim.SGD(meta_model_new.other_param, lr=args.meta_lr)\n",
    "\n",
    "\n",
    "loss_fn_ori = nn.CrossEntropyLoss().to(device)\n",
    "loss_fn_new = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7035c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n:  conv1.0.weight\n",
      "n:  conv1.0.bias\n",
      "n:  conv1.1.weight\n",
      "n:  conv1.1.bias\n",
      "n:  conv2.0.weight\n",
      "n:  conv2.0.bias\n",
      "n:  conv2.1.weight\n",
      "n:  conv2.1.bias\n",
      "n:  conv3.0.weight\n",
      "n:  conv3.0.bias\n",
      "n:  conv3.1.weight\n",
      "n:  conv3.1.bias\n",
      "n:  conv4.0.weight\n",
      "n:  conv4.0.bias\n",
      "n:  conv4.1.weight\n",
      "n:  conv4.1.bias\n",
      "n:  logits.weight\n",
      "n:  logits.bias\n"
     ]
    }
   ],
   "source": [
    "# make network parameters consistent\n",
    "for (n, p) in meta_model_ori.named_parameters():\n",
    "    print('n: ', n)\n",
    "    for i in range(len(n)):\n",
    "        if n[i] == '.' and n[i + 1].isdigit():\n",
    "            module1 = getattr(meta_model_ori, n[:i])[int(n[i+1])]\n",
    "            module2 = getattr(meta_model_new, n[:i])[int(n[i+1])]\n",
    "            getattr(module2, n[i+3:]).data.copy_(getattr(module1, n[i+3:]))\n",
    "            break\n",
    "    if 'logits' in n:\n",
    "        module1 = getattr(meta_model_ori, 'logits')\n",
    "        module2 = getattr(meta_model_new, 'logits')\n",
    "        getattr(module2, n[7:]).data.copy_(getattr(module1, n[7:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d93e382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('origin: ', OrderedDict(meta_model_ori.named_parameters())['logits.weight'][0,0])\n",
    "# print('new: ', meta_model_new.other_param[8][0,0])\n",
    "# print('origin: ', OrderedDict(meta_model_ori.named_parameters())['logits.bias'][0])\n",
    "# print('new: ', meta_model_new.other_param[9][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d21f6730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_meta_batch(n, k, q, meta_batch_size):\n",
    "    def prepare_meta_batch_(batch):\n",
    "        x, y = batch\n",
    "\n",
    "        # Reshape to `meta_batch_size` number of tasks. Each task contains\n",
    "        # n*k support samples to train the fast model on and q*k query samples to\n",
    "        # evaluate the fast model on and generate meta-gradients\n",
    "        x = x.reshape(meta_batch_size, n*k + q*k, num_input_channels, x.shape[-2], x.shape[-1])\n",
    "        # Move to device\n",
    "        x = x.double().to(device)\n",
    "        # Create label\n",
    "        y = create_nshot_task_label(k, q).cuda().repeat(meta_batch_size)\n",
    "        return x, y\n",
    "\n",
    "    return prepare_meta_batch_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1df045a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin grad:  tensor(3.1442e-17, device='cuda:1', dtype=torch.float64)\n",
      "origin w:  tensor(0.1569, device='cuda:1', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "new grad:  tensor(3.1008e-17, device='cuda:1', dtype=torch.float64)\n",
      "new w:  tensor(0.1569, device='cuda:1', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "origin grad:  tensor(-4.4235e-17, device='cuda:1', dtype=torch.float64)\n",
      "origin w:  tensor(0.1569, device='cuda:1', dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "new grad:  tensor(-5.0741e-17, device='cuda:1', dtype=torch.float64)\n",
      "new w:  tensor(0.1569, device='cuda:1', dtype=torch.float64, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dataloader=background_taskloader,\n",
    "prepare_batch=prepare_meta_batch(args.n, args.k, args.q, args.meta_batch_size)\n",
    "fit_function=meta_gradient_step,\n",
    "fit_function_kwargs={'n_shot': args.n, 'k_way': args.k, 'q_queries': args.q,\n",
    "                     'train': True,\n",
    "                     'order': args.order, 'device': device, 'inner_train_steps': args.inner_train_steps,\n",
    "                     'inner_lr': args.inner_lr}\n",
    "    \n",
    "for epoch in range(1, args.epochs+1):\n",
    "    for batch_index, batch in enumerate(dataloader[0]):\n",
    "        x, y = prepare_batch(batch)\n",
    "        x.requires_grad = False\n",
    "        y.requires_grad = False\n",
    "\n",
    "        loss_ori, y_pred_ori = meta_gradient_step_ori(meta_model_ori, optimiser_ori, loss_fn_ori, \n",
    "                                                     x, y, **fit_function_kwargs)\n",
    "        \n",
    "        print('origin grad: ', meta_model_ori.conv1[0].bias.grad[0])\n",
    "        print('origin w: ', meta_model_ori.conv1[0].bias[0])\n",
    "        \n",
    "        \n",
    "        loss_new, y_pred_new = meta_gradient_step_ori(meta_model_new, optimiser_new, loss_fn_new, \n",
    "                                                     x, y, **fit_function_kwargs)\n",
    "#         loss_new, y_pred_new = fit_function[0](meta_model_new, optimiser_new, loss_fn_new, x, y, origin=False, \n",
    "#                                        other_optim=[conv_optimiser_new, other_optimiser_new], \n",
    "#                                        p_task=[1,1,1,1], p_meta=[1,1,1,1], **fit_function_kwargs)\n",
    "    \n",
    "        print('new grad: ', meta_model_new.conv1[0].bias.grad[0])\n",
    "        print('new w: ', meta_model_new.conv1[0].bias[0])\n",
    "\n",
    "#         loss_ori, y_pred_ori = fit_function[0](meta_model_new, optimiser_new, loss_fn_new, x, y, origin=False, \n",
    "#                                                other_optim=[conv_optimiser_new, other_optimiser_new], \n",
    "#                                                p_task=[1,1,1,1], p_meta=[1,1,1,1], **fit_function_kwargs)\n",
    "\n",
    "#         loss_new, y_pred_new = fit_function[0](meta_model_new, optimiser_new, loss_fn_new, x, y, origin=True, \n",
    "#                                                other_optim=[conv_optimiser_new, other_optimiser_new], \n",
    "#                                                p_task=[1,1,1,1], p_meta=[1,1,1,1], **fit_function_kwargs)\n",
    "\n",
    "#         loss_ori, y_pred_ori = meta_gradient_step_ori(meta_model_ori, optimiser_ori, loss_fn_ori,\n",
    "#                                                   x, y, **fit_function_kwargs)\n",
    "\n",
    "#         print('old_grad')\n",
    "#         print(meta_model_ori.conv1[0].bias[0], meta_model_ori.conv1[0].bias.grad[0])\n",
    "\n",
    "#         loss_new, y_pred_new = meta_gradient_step_ori(meta_model_new, optimiser_new, loss_fn_new,\n",
    "#                                                   x, y, **fit_function_kwargs)\n",
    "\n",
    "#         print('new_grad')\n",
    "#         print(meta_model_ori.conv1[0].bias[0], meta_model_new.conv1[0].bias.grad[0])\n",
    "        \n",
    "# #         loss_new, y_pred_new = meta_gradient_step_ori(meta_model_ori, optimiser_new, loss_fn_new,\n",
    "# #                                                   x, y, **fit_function_kwargs)\n",
    "\n",
    "#         print('loss_ori: ', loss_ori)\n",
    "# #         print('y_pred_ori', y_pred_ori)\n",
    "#         print('loss_new: ', loss_new)\n",
    "# #         print('y_pred_new', y_pred_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "005ff7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1133, 0.1830, 0.1443, 0.4588, 0.1007], device='cuda:1',\n",
       "        dtype=torch.float64, grad_fn=<SelectBackward0>),\n",
       " tensor([0.1133, 0.1830, 0.1443, 0.4588, 0.1007], device='cuda:1',\n",
       "        dtype=torch.float64, grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# different output\n",
    "y_pred_new[0], y_pred_ori[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b52d3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1820,  0.1400,  0.0682],\n",
       "         [ 0.0558, -0.1389,  0.1704],\n",
       "         [ 0.1452, -0.1606,  0.1271]], device='cuda:1', dtype=torch.float64,\n",
       "        grad_fn=<SelectBackward0>),\n",
       " tensor([[ 0.1820,  0.1400,  0.0682],\n",
       "         [ 0.0558, -0.1389,  0.1704],\n",
       "         [ 0.1452, -0.1606,  0.1271]], device='cuda:1', dtype=torch.float64,\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters still consistent\n",
    "meta_model_ori.conv1[0].weight[0, 0], meta_model_new.conv1[0].weight[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89d12162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-4.4235e-17, device='cuda:1', dtype=torch.float64),\n",
       " tensor(-5.0741e-17, device='cuda:1', dtype=torch.float64))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_model_ori.conv1[0].bias.grad[0], meta_model_new.conv1[0].bias.grad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66a0ba3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.0.weight\n",
      "conv1.0.bias\n",
      "conv1.1.weight\n",
      "conv1.1.bias\n",
      "conv2.0.weight\n",
      "conv2.0.bias\n",
      "conv2.1.weight\n",
      "conv2.1.bias\n",
      "conv3.0.weight\n",
      "conv3.0.bias\n",
      "conv3.1.weight\n",
      "conv3.1.bias\n",
      "conv4.0.weight\n",
      "conv4.0.bias\n",
      "conv4.1.weight\n",
      "conv4.1.bias\n",
      "logits.weight\n",
      "logits.bias\n"
     ]
    }
   ],
   "source": [
    "for n, p in meta_model_new.named_parameters():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbdb7017",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2929393399.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [16]\u001b[0;36m\u001b[0m\n\u001b[0;31m    for n, p meta_model_ori.named_parameters():\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for n, p meta_model_ori.named_parameters():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f2f3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model_ori.conv1[0].bias.grad, meta_model_new.conv1[0].bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92411eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make network parameters consistent\n",
    "for (n, p) in meta_model_ori.named_parameters():\n",
    "    for i in range(len(n)):\n",
    "        if n[i] == '.' and n[i + 1].isdigit():\n",
    "            module1 = getattr(meta_model_ori, n[:i])[int(n[i+1])]\n",
    "            module2 = getattr(meta_model_new, n[:i])[int(n[i+1])]\n",
    "            print(torch.all((getattr(module2, n[i+3:]).grad == (getattr(module1, n[i+3:])).grad)))\n",
    "            break\n",
    "    if 'logits' in n:\n",
    "            module1 = getattr(meta_model_ori, 'logits')\n",
    "            module2 = getattr(meta_model_new, 'logits')\n",
    "            print(torch.all((getattr(module2, n[7:]).grad == (getattr(module1, n[7:])).grad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce96aa66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
